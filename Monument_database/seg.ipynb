{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('processed_vietnamese_texts_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns:\n",
      "['url', 'title', 'content', 'title_processed', 'title_normalized', 'title_token_count', 'content_processed', 'content_normalized', 'content_token_count']\n",
      "\n",
      "Dataset shape: (1163, 9)\n",
      "\n",
      "First row sample:\n",
      "                                                 url  \\\n",
      "0  https://dsvh.gov.vn/le-cung-ban-vuong-cua-nguo...   \n",
      "1  https://dsvh.gov.vn/le-cau-mua-cua-nguoi-co-la...   \n",
      "2  https://dsvh.gov.vn/nghe-thuat-che-bien-mon-an...   \n",
      "3  https://dsvh.gov.vn/nghe-thuat-mua-khen-cua-ng...   \n",
      "4     https://dsvh.gov.vn/le-hoi-dinh-thay-thim-3454   \n",
      "\n",
      "                                        title  \\\n",
      "0          Lễ cúng Bàn vương của người Dao đỏ   \n",
      "1              Lễ cầu mùa của người Cờ Lao đỏ   \n",
      "2  Nghệ thuật chế biến món ăn chay ở Tây Ninh   \n",
      "3          Nghệ thuật múa Khèn của người Mông   \n",
      "4                       Lễ hội dinh Thầy Thím   \n",
      "\n",
      "                                             content        title_processed  \\\n",
      "0  Người Dao đỏ (xã Hồ Thầu, huyện Hoàng Su Phì, ...             Lễ cúng đỏ   \n",
      "1  Lễ cầu mùa của người Cờ Lao đỏ (xã Túng Sán, h...              Lễ cầu đỏ   \n",
      "2  Tây Ninh có 04 tôn giáo chính: Phật giáo, Thiê...    Nghệ thuật chế biến   \n",
      "3  Khèn (tiếng Mông gọi là Khềnh, Kềnh, Kỳ) là nh...             Nghệ thuật   \n",
      "4  Dinh Thầy Thím tọa lạc giữa khu rừng dầu Bàu C...  Lễ hội dinh Thầy Thím   \n",
      "\n",
      "        title_normalized  title_token_count  \\\n",
      "0             Le cung do                  2   \n",
      "1              Le cau do                  3   \n",
      "2    Nghe thuat che bien                  2   \n",
      "3             Nghe thuat                  1   \n",
      "4  Le hoi dinh Thay Thim                  3   \n",
      "\n",
      "                                   content_processed  \\\n",
      "0  đỏ Phì hộ vệ thủy thân trống lột trống tế lễ c...   \n",
      "1  Lễ cầu đỏ Phì ra miếu thờ Hoàn Vần Thùng vị mù...   \n",
      "2  chùa tịnh xá Các chùa cúng chay quanh năm mùng...   \n",
      "3  Khèn Cùng với thầy cúng kính trọng lỗ gọt thân...   \n",
      "4  Dinh Thầy thôn Tam Tân xã Tân Tiến thị xã La G...   \n",
      "\n",
      "                                  content_normalized  content_token_count  \n",
      "0  do Phi ho ve thuy than trong lot trong te le c...                  197  \n",
      "1  Le cau do Phi ra mieu tho Hoan Van Thung vi mu...                  152  \n",
      "2  chua tinh xa Cac chua cung chay quanh nam mung...                  179  \n",
      "3  Khen Cung voi thay cung kinh trong lo got than...                  184  \n",
      "4  Dinh Thay thon Tam Tan xa Tan Tien thi xa La G...                  205  \n"
     ]
    }
   ],
   "source": [
    "# Let's first examine the structure with just 1 row as requested\n",
    "print(\"Dataset columns:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nFirst row sample:\")\n",
    "sample_row = df.iloc[0:5]\n",
    "print(sample_row)\n",
    "\n",
    "# Save just 1 row for reference as requested\n",
    "# df[0:1].to_csv('sample_ref.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Vietnamese NER with underthesea - handling 4-tuple format\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_entities_fixed(text):\n",
    "    \"\"\"Extract entities using underthesea NER - fixed for 4-tuple format\"\"\"\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        ner_results = ner(text[:800])  # Slightly longer text for better context\n",
    "        \n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        current_type = None\n",
    "        \n",
    "        for result in ner_results:\n",
    "            # Handle the 4-tuple format: (word, pos_tag, chunk_tag, ner_tag)\n",
    "            if isinstance(result, tuple):\n",
    "                if len(result) == 4:\n",
    "                    word, pos_tag, chunk_tag, ner_tag = result\n",
    "                elif len(result) == 3:\n",
    "                    word, pos_tag, ner_tag = result\n",
    "                elif len(result) == 2:\n",
    "                    word, ner_tag = result\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Process NER tags (B-*, I-*, O)\n",
    "            if ner_tag.startswith('B-'):  # Beginning of entity\n",
    "                # Save previous entity if exists\n",
    "                if current_entity and current_type:\n",
    "                    entity_text = ' '.join(current_entity).strip()\n",
    "                    if len(entity_text) > 1:  # Skip single characters\n",
    "                        entities.append({\n",
    "                            'text': entity_text,\n",
    "                            'type': current_type\n",
    "                        })\n",
    "                \n",
    "                # Start new entity\n",
    "                current_entity = [word]\n",
    "                current_type = ner_tag[2:]  # Remove 'B-' prefix\n",
    "                \n",
    "            elif ner_tag.startswith('I-') and current_type == ner_tag[2:]:\n",
    "                # Continue current entity\n",
    "                current_entity.append(word)\n",
    "                \n",
    "            else:\n",
    "                # End current entity (O tag or different entity type)\n",
    "                if current_entity and current_type:\n",
    "                    entity_text = ' '.join(current_entity).strip()\n",
    "                    if len(entity_text) > 1:\n",
    "                        entities.append({\n",
    "                            'text': entity_text,\n",
    "                            'type': current_type\n",
    "                        })\n",
    "                current_entity = []\n",
    "                current_type = None\n",
    "        \n",
    "        # Don't forget the last entity\n",
    "        if current_entity and current_type:\n",
    "            entity_text = ' '.join(current_entity).strip()\n",
    "            if len(entity_text) > 1:\n",
    "                entities.append({\n",
    "                    'text': entity_text,\n",
    "                    'type': current_type\n",
    "                })\n",
    "        \n",
    "        return entities\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in NER: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_vietnamese_heritage_texts(df, num_docs=10):\n",
    "    \"\"\"Process Vietnamese heritage texts with entity extraction\"\"\"\n",
    "    print(f\"🏛️ Processing {num_docs} Vietnamese heritage documents...\")\n",
    "    \n",
    "    all_entities = defaultdict(list)\n",
    "    doc_entities = []\n",
    "    \n",
    "    for idx, row in df.head(num_docs).iterrows():\n",
    "        title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "        content = str(row['content']) if pd.notna(row['content']) else \"\"\n",
    "        full_text = f\"{title} {content}\"\n",
    "        \n",
    "        print(f\"\\n📜 Document {idx+1}: {title[:60]}...\")\n",
    "        \n",
    "        # Extract all entities\n",
    "        entities = extract_entities_fixed(full_text)\n",
    "        \n",
    "        # Categorize entities\n",
    "        locations = [e for e in entities if e['type'] in ['LOC', 'LOCATION']]\n",
    "        people = [e for e in entities if e['type'] in ['PER', 'PERSON']]\n",
    "        organizations = [e for e in entities if e['type'] in ['ORG', 'ORGANIZATION']]\n",
    "        \n",
    "        doc_info = {\n",
    "            'doc_index': idx,\n",
    "            'title': title,\n",
    "            'total_entities': len(entities),\n",
    "            'locations': locations,\n",
    "            'people': people,\n",
    "            'organizations': organizations,\n",
    "            'all_entities': entities\n",
    "        }\n",
    "        doc_entities.append(doc_info)\n",
    "        \n",
    "        # Add to global collection\n",
    "        for entity in entities:\n",
    "            all_entities[entity['type']].append({\n",
    "                'text': entity['text'],\n",
    "                'doc_title': title,\n",
    "                'doc_index': idx\n",
    "            })\n",
    "        \n",
    "        # Print quick summary for this doc\n",
    "        print(f\"   ✅ Found {len(entities)} entities:\")\n",
    "        if len(entities) > 0:\n",
    "            entity_types = list(set([e['type'] for e in entities]))\n",
    "            for et in entity_types:\n",
    "                count = len([e for e in entities if e['type'] == et])\n",
    "                examples = [e['text'] for e in entities if e['type'] == et][:3]\n",
    "                print(f\"      {et}: {count} entities - {', '.join(examples)}\")\n",
    "        else:\n",
    "            print(\"      No entities found\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n🎯 HERITAGE ENTITY SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    for entity_type, entities in all_entities.items():\n",
    "        unique_entities = list(set([e['text'] for e in entities]))\n",
    "        print(f\"{entity_type}: {len(entities)} total, {len(unique_entities)} unique\")\n",
    "        \n",
    "        # Show top examples\n",
    "        for i, entity in enumerate(unique_entities[:5]):\n",
    "            count = len([e for e in entities if e['text'] == entity])\n",
    "            print(f\"  • {entity} (appears {count} times)\")\n",
    "        if len(unique_entities) > 5:\n",
    "            print(f\"  ... and {len(unique_entities)-5} more unique entities\")\n",
    "        print()\n",
    "    \n",
    "    return all_entities, doc_entities\n",
    "\n",
    "# Import NER function\n",
    "from underthesea import ner\n",
    "\n",
    "# Test the fixed version\n",
    "print(\"🚀 Testing FIXED underthesea NER on Vietnamese heritage texts...\")\n",
    "entities, doc_details = process_vietnamese_heritage_texts(df, num_docs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
