#!/usr/bin/env python3
"""
Test Ranking Display - Test the detailed ranking information display
"""

import sys
import os
import json

# Add the search_engine directory to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from search_core import HistoricalSearchEngine

def test_ranking_details():
    """Test the detailed ranking information"""
    print("üéØ Testing Detailed Ranking Information")
    print("=" * 50)
    
    # Initialize search engine
    print("Loading search engine...")
    engine = HistoricalSearchEngine()
    engine._ensure_loaded()
    print("‚úÖ Search engine loaded")
    print()
    
    # Test different search types
    test_cases = [
        ("H·ªì Ch√≠ Minh", "entity"),
        ("chi·∫øn tranh Vi·ªát Nam", "text"),
        ("Nguy·ªÖn √Åi Qu·ªëc", "hybrid"),
    ]
    
    for query, search_type in test_cases:
        print(f"üîç Testing {search_type.upper()} search: '{query}'")
        print("-" * 40)
        
        # Perform search
        if search_type == "entity":
            results = engine.search_by_entity(query, fuzzy=True, limit=3)
        elif search_type == "text":
            results = engine.search_text(query, limit=3)
        elif search_type == "hybrid":
            results = engine.hybrid_search(query, limit=3)
        
        # Display results with ranking details
        if results['documents']:
            for i, doc in enumerate(results['documents'][:2]):  # Show top 2 results
                print(f"\nüìÑ Result {i+1}: {doc['title'][:60]}...")
                
                # Display main score
                score = doc.get('score', doc.get('combined_score', 0))
                print(f"   üéØ Final Score: {score:.2f}")
                
                # Display ranking details
                if 'ranking_details' in doc and doc['ranking_details']:
                    print("   üìä Ranking Breakdown:")
                    
                    if search_type == "entity" and isinstance(doc['ranking_details'], list):
                        for j, detail in enumerate(doc['ranking_details']):
                            print(f"      Entity {j+1}: {detail.get('entity_name', 'N/A')}")
                            print(f"        ‚Ä¢ Base Score: {detail.get('base_score', 0):.2f}")
                            print(f"        ‚Ä¢ Similarity: {detail.get('similarity', 0):.2f}")
                            print(f"        ‚Ä¢ Context Relevance: {detail.get('context_relevance', 1):.2f}x")
                            print(f"        ‚Ä¢ Quality Boost: {detail.get('quality_boost', 1):.2f}x")
                            print(f"        ‚Ä¢ Position Score: {detail.get('position_score', 1):.2f}x")
                            if detail.get('in_title'):
                                print(f"        ‚Ä¢ Title Boost: {detail.get('title_boost', 1):.2f}x")
                            print(f"        ‚Ä¢ Final Score: {detail.get('final_score', 0):.2f}")
                    
                    elif search_type == "text":
                        detail = doc['ranking_details']
                        print(f"      ‚Ä¢ Base Score: {detail.get('base_score', 0):.2f}")
                        print(f"      ‚Ä¢ Title Matches: {detail.get('title_matches', 0)}")
                        print(f"      ‚Ä¢ Content Matches: {detail.get('content_matches', 0)}")
                        print(f"      ‚Ä¢ TF-IDF Contribution: {detail.get('tf_idf_contribution', 0):.2f}")
                        print(f"      ‚Ä¢ Query Coverage: {(detail.get('query_coverage', 0) * 100):.1f}%")
                        print(f"      ‚Ä¢ Coverage Boost: {detail.get('coverage_boost', 1):.2f}x")
                        print(f"      ‚Ä¢ Quality Boost: {detail.get('quality_boost', 1):.2f}x")
                        print(f"      ‚Ä¢ Title Boost: {detail.get('title_boost', 1):.2f}x")
                    
                    elif search_type == "hybrid":
                        detail = doc['ranking_details']
                        print(f"      ‚Ä¢ Entity Score: {detail.get('entity_score', 0):.2f}")
                        print(f"      ‚Ä¢ Text Score: {detail.get('text_score', 0):.2f}")
                        print(f"      ‚Ä¢ Dual Match Bonus: {'Yes' if detail.get('dual_match_bonus') else 'No'}")
                        print(f"      ‚Ä¢ Combined Score: {detail.get('final_combined_score', 0):.2f}")
                else:
                    print("   ‚ö†Ô∏è  No ranking details available")
        else:
            print("   ‚ùå No results found")
        
        print("\n" + "=" * 50)
    
    print("\nüéâ Ranking details test completed!")
    print("\nüí° To see this in the web interface:")
    print("   1. Start the API: python search_engine/api.py")
    print("   2. Open: http://localhost:5001")
    print("   3. Search for any query")
    print("   4. Click 'Show Ranking Details' for detailed breakdown")

def test_score_transparency():
    """Test score transparency and user understanding"""
    print("\nüîç Testing Score Transparency")
    print("=" * 40)
    
    engine = HistoricalSearchEngine()
    engine._ensure_loaded()
    
    # Test a specific query to show score breakdown
    query = "H·ªì Ch√≠ Minh"
    results = engine.search_by_entity(query, fuzzy=True, limit=1)
    
    if results['documents']:
        doc = results['documents'][0]
        print(f"Query: '{query}'")
        print(f"Top Result: {doc['title'][:50]}...")
        print(f"Final Score: {doc['score']:.2f}")
        
        if 'ranking_details' in doc and doc['ranking_details']:
            detail = doc['ranking_details'][0]
            print("\nüßÆ Score Calculation:")
            print(f"  Base Score = Entity Frequency √ó Similarity")
            print(f"             = {detail.get('entity_frequency', 0)} √ó {detail.get('similarity', 0):.2f}")
            print(f"             = {detail.get('base_score', 0):.2f}")
            print()
            print(f"  Final Score = Base Score √ó Context √ó Quality √ó Position √ó Title √ó Match √ó Type")
            print(f"              = {detail.get('base_score', 0):.2f} √ó {detail.get('context_relevance', 1):.2f} √ó {detail.get('quality_boost', 1):.2f} √ó {detail.get('position_score', 1):.2f} √ó {detail.get('title_boost', 1):.2f} √ó {detail.get('exact_match_bonus', 1):.2f} √ó {detail.get('type_relevance', 1):.2f}")
            print(f"              = {detail.get('final_score', 0):.2f}")
            print()
            print("‚úÖ Users can now see exactly how scores are calculated!")

if __name__ == "__main__":
    try:
        test_ranking_details()
        test_score_transparency()
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Test interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
